{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1) Mount Colab."
      ],
      "metadata": {
        "id": "qifafZdmfzyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VKH8MEYfz8J",
        "outputId": "995b3086-43e5-4b39-99eb-fd959c12d3ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Inspect the thoroughly cleaned train dataset."
      ],
      "metadata": {
        "id": "YmOP7DlTixb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "train_dir = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Datasets/crime_train_final.csv\"\n",
        "df = pd.read_csv(train_dir)\n",
        "\n",
        "# Check datatypes\n",
        "print(df.dtypes)\n",
        "\n",
        "# Count numerical and categorical columns\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns\n",
        "\n",
        "print(f\"Numerical columns ({len(num_cols)}): {list(num_cols)}\")\n",
        "print(f\"Categorical columns ({len(cat_cols)}): {list(cat_cols)}\")"
      ],
      "metadata": {
        "id": "_kv4XTolgshy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46b5be8-650f-476b-e0ed-5bf1dadf73f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "highest_offense_description     object\n",
            "highest_offense_code             int64\n",
            "family_violence                 object\n",
            "occurred_date_time_year          int64\n",
            "sine_odt_month                 float64\n",
            "cosine_odt_month               float64\n",
            "sine_odt_week_of_year          float64\n",
            "cosine_odt_week_of_year        float64\n",
            "sine_odt_day                   float64\n",
            "cosine_odt_day                 float64\n",
            "sine_odt_day_of_week           float64\n",
            "cosine_odt_day_of_week         float64\n",
            "sine_odt_hour                  float64\n",
            "cosine_odt_hour                float64\n",
            "sine_odt_minute                float64\n",
            "cosine_odt_minute              float64\n",
            "sine_occurred_time             float64\n",
            "cosine_occurred_time           float64\n",
            "sine_report_time               float64\n",
            "cosine_report_time             float64\n",
            "report_date_time_year            int64\n",
            "sine_rdt_week_of_year          float64\n",
            "cosine_rdt_week_of_year        float64\n",
            "sine_rdt_day                   float64\n",
            "cosine_rdt_day                 float64\n",
            "sine_rdt_hour                  float64\n",
            "cosine_rdt_hour                float64\n",
            "sine_rdt_minute                float64\n",
            "cosine_rdt_minute              float64\n",
            "sine_rdt_month                 float64\n",
            "cosine_rdt_month               float64\n",
            "sine_rdt_day_of_week           float64\n",
            "cosine_rdt_day_of_week         float64\n",
            "location_type                   object\n",
            "apd_sector                      object\n",
            "apd_district                     int64\n",
            "clearance_status                object\n",
            "dtype: object\n",
            "Numerical columns (32): ['highest_offense_code', 'occurred_date_time_year', 'sine_odt_month', 'cosine_odt_month', 'sine_odt_week_of_year', 'cosine_odt_week_of_year', 'sine_odt_day', 'cosine_odt_day', 'sine_odt_day_of_week', 'cosine_odt_day_of_week', 'sine_odt_hour', 'cosine_odt_hour', 'sine_odt_minute', 'cosine_odt_minute', 'sine_occurred_time', 'cosine_occurred_time', 'sine_report_time', 'cosine_report_time', 'report_date_time_year', 'sine_rdt_week_of_year', 'cosine_rdt_week_of_year', 'sine_rdt_day', 'cosine_rdt_day', 'sine_rdt_hour', 'cosine_rdt_hour', 'sine_rdt_minute', 'cosine_rdt_minute', 'sine_rdt_month', 'cosine_rdt_month', 'sine_rdt_day_of_week', 'cosine_rdt_day_of_week', 'apd_district']\n",
            "Categorical columns (5): ['highest_offense_description', 'family_violence', 'location_type', 'apd_sector', 'clearance_status']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Convert the apd_district and highest_offense_code alone to categorical."
      ],
      "metadata": {
        "id": "B5FU_2SyjaD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_convert = ['apd_district', 'highest_offense_code']\n",
        "\n",
        "for col in cat_convert:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "print(df[cat_convert].dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqknJpFrjcmy",
        "outputId": "b1103c24-4267-4326-df92-f6e1c6b2425c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apd_district            category\n",
            "highest_offense_code    category\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Load and inspect the test dataset."
      ],
      "metadata": {
        "id": "T05tAoTXjmom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "test_dir = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Datasets/crime_test_cleaned.csv\"\n",
        "df = pd.read_csv(test_dir)\n",
        "\n",
        "# Check datatypes\n",
        "print(df.dtypes)\n",
        "\n",
        "# Count numerical and categorical columns\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns\n",
        "\n",
        "print(f\"Numerical columns ({len(num_cols)}): {list(num_cols)}\")\n",
        "print(f\"Categorical columns ({len(cat_cols)}): {list(cat_cols)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiCNFqH7jm1C",
        "outputId": "f3321cc2-ffa8-4945-92a7-0810cffe4b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "highest_offense_description     object\n",
            "highest_offense_code             int64\n",
            "family_violence                 object\n",
            "occurred_date_time_year          int64\n",
            "sine_odt_month                 float64\n",
            "cosine_odt_month               float64\n",
            "sine_odt_week_of_year          float64\n",
            "cosine_odt_week_of_year        float64\n",
            "sine_odt_day                   float64\n",
            "cosine_odt_day                 float64\n",
            "sine_odt_day_of_week           float64\n",
            "cosine_odt_day_of_week         float64\n",
            "sine_odt_hour                  float64\n",
            "cosine_odt_hour                float64\n",
            "sine_odt_minute                float64\n",
            "cosine_odt_minute              float64\n",
            "sine_occurred_time             float64\n",
            "cosine_occurred_time           float64\n",
            "sine_report_time               float64\n",
            "cosine_report_time             float64\n",
            "report_date_time_year            int64\n",
            "sine_rdt_week_of_year          float64\n",
            "cosine_rdt_week_of_year        float64\n",
            "sine_rdt_day                   float64\n",
            "cosine_rdt_day                 float64\n",
            "sine_rdt_hour                  float64\n",
            "cosine_rdt_hour                float64\n",
            "sine_rdt_minute                float64\n",
            "cosine_rdt_minute              float64\n",
            "sine_rdt_month                 float64\n",
            "cosine_rdt_month               float64\n",
            "sine_rdt_day_of_week           float64\n",
            "cosine_rdt_day_of_week         float64\n",
            "location_type                   object\n",
            "apd_sector                      object\n",
            "apd_district                     int64\n",
            "clearance_status                object\n",
            "dtype: object\n",
            "Numerical columns (32): ['highest_offense_code', 'occurred_date_time_year', 'sine_odt_month', 'cosine_odt_month', 'sine_odt_week_of_year', 'cosine_odt_week_of_year', 'sine_odt_day', 'cosine_odt_day', 'sine_odt_day_of_week', 'cosine_odt_day_of_week', 'sine_odt_hour', 'cosine_odt_hour', 'sine_odt_minute', 'cosine_odt_minute', 'sine_occurred_time', 'cosine_occurred_time', 'sine_report_time', 'cosine_report_time', 'report_date_time_year', 'sine_rdt_week_of_year', 'cosine_rdt_week_of_year', 'sine_rdt_day', 'cosine_rdt_day', 'sine_rdt_hour', 'cosine_rdt_hour', 'sine_rdt_minute', 'cosine_rdt_minute', 'sine_rdt_month', 'cosine_rdt_month', 'sine_rdt_day_of_week', 'cosine_rdt_day_of_week', 'apd_district']\n",
            "Categorical columns (5): ['highest_offense_description', 'family_violence', 'location_type', 'apd_sector', 'clearance_status']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Convert those columns back to categorical as we face the same problem with the test dataset as well."
      ],
      "metadata": {
        "id": "c4BbKdz2j-aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_convert = ['apd_district', 'highest_offense_code']\n",
        "\n",
        "for col in cat_convert:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "print(df[cat_convert].dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMvQxgsOj-iz",
        "outputId": "ddcfc267-fb6c-48d5-adc9-7377fb851cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apd_district            category\n",
            "highest_offense_code    category\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Check for NAs in both of them."
      ],
      "metadata": {
        "id": "rrn53CcSkpte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load train\n",
        "train_dir = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Datasets/crime_train_final.csv\"\n",
        "df_train = pd.read_csv(train_dir)\n",
        "\n",
        "# Load test\n",
        "test_dir = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Datasets/crime_test_cleaned.csv\"\n",
        "df_test = pd.read_csv(test_dir)\n",
        "\n",
        "# Check for NAs in train\n",
        "if df_train.isna().sum().sum() == 0:\n",
        "    print(\"No NAs in train dataset.\")\n",
        "else:\n",
        "    print(\"There are missing values in train dataset.\")\n",
        "\n",
        "# Check for NAs in test\n",
        "if df_test.isna().sum().sum() == 0:\n",
        "    print(\"No NAs in test dataset.\")\n",
        "else:\n",
        "    print(\"There are missing values in test dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_wa40sckp3G",
        "outputId": "cce658f3-ad18-4912-cedc-e5c0039d3834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NAs in train dataset.\n",
            "No NAs in test dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Java Script for keeping code alive."
      ],
      "metadata": {
        "id": "nVjjjcXAvZ31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript, display\n",
        "\n",
        "# Inject JS that clicks the \"Connect\"/\"Reconnect\" button every minute\n",
        "js_code = \"\"\"\n",
        "function ClickConnect() {\n",
        "  const btn = document.querySelector('colab-connect-button') ||\n",
        "              document.querySelector('#top-toolbar > colab-connect-button');\n",
        "  if (btn) {\n",
        "    // Click the inner shadow-root's \"connect\" button if needed\n",
        "    const inner = btn.shadowRoot ? btn.shadowRoot.querySelector('#connect') : null;\n",
        "    (inner || btn).click();\n",
        "    console.log('ğŸŸ¢ ClickConnect clicked at', new Date().toLocaleTimeString());\n",
        "  } else {\n",
        "    console.log('âš ï¸ Connect button not found');\n",
        "  }\n",
        "}\n",
        "setInterval(ClickConnect, 60000);\n",
        "\"\"\"\n",
        "display(Javascript(js_code))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sOnrB-HTvaEt",
        "outputId": "74134891-4f92-477e-9435-0c6bc7d47174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "function ClickConnect() {\n",
              "  const btn = document.querySelector('colab-connect-button') ||\n",
              "              document.querySelector('#top-toolbar > colab-connect-button');\n",
              "  if (btn) {\n",
              "    // Click the inner shadow-root's \"connect\" button if needed\n",
              "    const inner = btn.shadowRoot ? btn.shadowRoot.querySelector('#connect') : null;\n",
              "    (inner || btn).click();\n",
              "    console.log('ğŸŸ¢ ClickConnect clicked at', new Date().toLocaleTimeString());\n",
              "  } else {\n",
              "    console.log('âš ï¸ Connect button not found');\n",
              "  }\n",
              "}\n",
              "setInterval(ClickConnect, 60000);\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Modelling - TabNet\n",
        "\n",
        "Note: The balanced accuracy, and recall are lame parameters. So they were not used in the report."
      ],
      "metadata": {
        "id": "PIe_xAZStmoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm0FcJoVwTyp",
        "outputId": "5772e4a9-4d7c-4145-d7ea-5a67cbeaba0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ SETUP ==============\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             balanced_accuracy_score, confusion_matrix)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import random\n",
        "import time\n",
        "\n",
        "# -------- Reproducibility --------\n",
        "SEED = 1906525\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 1. Paths\n",
        "train_path = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Datasets/crime_train_final.csv\"\n",
        "test_path = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Datasets/crime_test_cleaned.csv\"\n",
        "perf_dir = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Results/TabNet/Performance Metrics\"\n",
        "cm_dir = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Results/TabNet/Confusion Matrices\"\n",
        "test_pred_dir = \"/content/drive/MyDrive/Big Data Analysis and Project - a1906525/Results/TabNet/Test Results\"\n",
        "\n",
        "os.makedirs(perf_dir, exist_ok=True)\n",
        "os.makedirs(cm_dir, exist_ok=True)\n",
        "os.makedirs(test_pred_dir, exist_ok=True)\n",
        "\n",
        "# 2. Load Data\n",
        "df_train = pd.read_csv(train_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# 3. Categorical Columns\n",
        "cat_cols = ['highest_offense_description', 'family_violence', 'location_type',\n",
        "            'apd_sector', 'clearance_status', 'apd_district', 'highest_offense_code']\n",
        "for col in cat_cols:\n",
        "    df_train[col] = df_train[col].astype('category')\n",
        "    df_test[col] = df_test[col].astype('category')\n",
        "\n",
        "# 4. Features/Target\n",
        "features = [col for col in df_train.columns if col != \"clearance_status\"]\n",
        "target = \"clearance_status\"\n",
        "\n",
        "# For all categorical feature columns except target\n",
        "feature_cat_cols = [col for col in cat_cols if col != target]\n",
        "for col in feature_cat_cols:\n",
        "    df_train[col] = df_train[col].cat.codes\n",
        "    df_test[col] = df_test[col].cat.codes\n",
        "\n",
        "# 5. Train/Val split (stratified, reproducible)\n",
        "train, val = train_test_split(df_train, test_size=0.2, stratify=df_train[target], random_state=SEED)\n",
        "\n",
        "# 6. TabNet categorical requirements\n",
        "cat_idxs = [features.index(col) for col in feature_cat_cols]\n",
        "cat_dims = [df_train[col].nunique() for col in feature_cat_cols]\n",
        "\n",
        "def get_y_codes(df, target):\n",
        "    return df[target].cat.codes.values\n",
        "\n",
        "def get_labels(df, target):\n",
        "    return list(df[target].cat.categories)\n",
        "\n",
        "# Helper for metrics\n",
        "def compute_metrics(y_true, y_pred, labels):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
        "    # Handle binary\n",
        "    if cm.shape == (2,2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        specificity = tn / (tn + fp) if (tn + fp) else 0\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) else 0\n",
        "    else:\n",
        "        specificity = sensitivity = 0\n",
        "    return cm, specificity, sensitivity\n",
        "\n",
        "# =============== MAIN LOOP ================\n",
        "\n",
        "param_grid = {\n",
        "    'max_epochs': [5,10,20,35,50],\n",
        "    'n_a': [8,16,32,48,64],  # n_d = n_a\n",
        "}\n",
        "\n",
        "# Initialize dataframe for all results\n",
        "all_results = []\n",
        "\n",
        "for n_a in param_grid['n_a']:\n",
        "    for epoch in param_grid['max_epochs']:\n",
        "        print(f\"\\nRunning TabNet: n_a/n_d={n_a}, epochs={epoch}\")\n",
        "        # Simulate per-epoch progress bar\n",
        "        for i in range(1, epoch+1):\n",
        "            print(f\"{i}/{epoch} epoch completed...\", end=\"\\r\")\n",
        "            # time.sleep(0.2)  # just to make it visible; remove if running for speed\n",
        "\n",
        "        # Model\n",
        "        clf = TabNetClassifier(\n",
        "            n_d=n_a, n_a=n_a, cat_idxs=cat_idxs, cat_dims=cat_dims, cat_emb_dim=1,\n",
        "            optimizer_fn=torch.optim.Adam,\n",
        "            seed=SEED, verbose=0\n",
        "        )\n",
        "        # Fit\n",
        "        clf.fit(\n",
        "            X_train=train[features].values, y_train=get_y_codes(train, target),\n",
        "            eval_set=[(val[features].values, get_y_codes(val, target))],\n",
        "            eval_name=['val'],\n",
        "            eval_metric=['accuracy'],\n",
        "            max_epochs=epoch, patience=10, batch_size=1024, virtual_batch_size=128,\n",
        "            num_workers=0, drop_last=False\n",
        "        )\n",
        "        print(f\"{epoch}/{epoch} epoch completed. (Model training finished for n_a={n_a})\")\n",
        "\n",
        "        # Predict as codes\n",
        "        train_preds = clf.predict(train[features].values)\n",
        "        val_preds   = clf.predict(val[features].values)\n",
        "        test_preds  = clf.predict(df_test[features].values)\n",
        "\n",
        "        # Get the string labels\n",
        "        labels = get_labels(train, target)\n",
        "        train_y = get_y_codes(train, target)\n",
        "        val_y   = get_y_codes(val, target)\n",
        "        test_y  = get_y_codes(df_test, target)\n",
        "\n",
        "        # Probabilities for loss\n",
        "        train_probs = clf.predict_proba(train[features].values)\n",
        "        val_probs   = clf.predict_proba(val[features].values)\n",
        "        test_probs  = clf.predict_proba(df_test[features].values)\n",
        "\n",
        "        # Metrics\n",
        "        train_acc = accuracy_score(train_y, train_preds)\n",
        "        val_acc   = accuracy_score(val_y, val_preds)\n",
        "        test_acc  = accuracy_score(test_y, test_preds)\n",
        "        train_loss = -np.mean(np.log(train_probs[np.arange(len(train_y)), train_y]))\n",
        "        val_loss   = -np.mean(np.log(val_probs[np.arange(len(val_y)), val_y]))\n",
        "        test_loss  = -np.mean(np.log(test_probs[np.arange(len(test_y)), test_y]))\n",
        "\n",
        "        # Classification metrics for test set (binary: \"C\" is positive)\n",
        "        pos_label = labels.index(\"C\")\n",
        "        prec = precision_score(test_y, test_preds, pos_label=pos_label, average='binary')\n",
        "        rec  = recall_score(test_y, test_preds, pos_label=pos_label, average='binary')\n",
        "        f1   = f1_score(test_y, test_preds, pos_label=pos_label, average='binary')\n",
        "        bal_acc = balanced_accuracy_score(test_y, test_preds)\n",
        "        cm, specificity, sensitivity = compute_metrics(test_y, test_preds, labels)\n",
        "\n",
        "        # Save current results to all_results list\n",
        "        result = {\n",
        "            'Model': 'TabNet',\n",
        "            'na_nd': n_a,\n",
        "            'epoch': epoch,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_accuracy': val_acc,\n",
        "            'test_accuracy': test_acc,\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'test_loss': test_loss,\n",
        "            'precision': prec,\n",
        "            'recall': rec,\n",
        "            'f1': f1,\n",
        "            'balanced_accuracy': bal_acc,\n",
        "            'specificity': specificity,\n",
        "            'sensitivity': sensitivity\n",
        "        }\n",
        "        all_results.append(result)\n",
        "\n",
        "        # Save confusion matrix (same as before)\n",
        "        fname = f\"{n_a}na_{epoch}epch.csv\"\n",
        "        plt.figure(figsize=(4,4))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=labels, yticklabels=labels)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.title(f\"Confusion Matrix (Test) - {n_a}na, {epoch}epch\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(cm_dir, fname.replace('.csv','.png')))\n",
        "        plt.close()\n",
        "\n",
        "        # Save 15 random test rows (actual & predicted in string form, predicted after actual)\n",
        "        test_results = df_test.copy()\n",
        "        # predicted_clearance_status in string form\n",
        "        test_results['predicted_clearance_status'] = [labels[p] for p in test_preds]\n",
        "        # Place predicted_clearance_status column next to clearance_status\n",
        "        cols = list(test_results.columns)\n",
        "        cols.insert(cols.index('clearance_status') + 1, cols.pop(cols.index('predicted_clearance_status')))\n",
        "        test_results = test_results[cols]\n",
        "        # Save sample\n",
        "        sample = test_results.sample(15, random_state=SEED)\n",
        "        sample.to_csv(os.path.join(test_pred_dir, fname.replace('.csv','_predicted.csv')), index=False)\n",
        "\n",
        "        print(f\"Saved: {fname}\")\n",
        "        print(f\"Training accuracy: {train_acc:.4f} | Testing accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Save ALL results to a single Excel file (tabnet_all_results.xlsx)\n",
        "df_all = pd.DataFrame(all_results)\n",
        "excel_path = os.path.join(perf_dir, \"TabNet_all_results.xlsx\")\n",
        "df_all.to_excel(excel_path, index=False)\n",
        "print(f\"All results saved to {excel_path}\")\n",
        "print(\"All hyperparameter combinations are complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBpSmxmhtmxA",
        "outputId": "d69a0679-66b5-48c0-d8cf-f81a6657112a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running TabNet: n_a/n_d=8, epochs=5\n",
            "1/5 epoch completed...\r2/5 epoch completed...\r3/5 epoch completed...\r4/5 epoch completed...\r5/5 epoch completed...\rStop training because you reached max_epochs = 5 with best_epoch = 4 and best_val_accuracy = 0.82649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 epoch completed. (Model training finished for n_a=8)\n",
            "Saved: 8na_5epch.csv\n",
            "Training accuracy: 0.8273 | Testing accuracy: 0.7404\n",
            "\n",
            "Running TabNet: n_a/n_d=8, epochs=10\n",
            "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_accuracy = 0.87634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 epoch completed. (Model training finished for n_a=8)\n",
            "Saved: 8na_10epch.csv\n",
            "Training accuracy: 0.8793 | Testing accuracy: 0.6195\n",
            "\n",
            "Running TabNet: n_a/n_d=8, epochs=20\n",
            "Stop training because you reached max_epochs = 20 with best_epoch = 18 and best_val_accuracy = 0.87911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 epoch completed. (Model training finished for n_a=8)\n",
            "Saved: 8na_20epch.csv\n",
            "Training accuracy: 0.8829 | Testing accuracy: 0.6293\n",
            "\n",
            "Running TabNet: n_a/n_d=8, epochs=35\n",
            "Stop training because you reached max_epochs = 35 with best_epoch = 33 and best_val_accuracy = 0.88086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 epoch completed. (Model training finished for n_a=8)\n",
            "Saved: 8na_35epch.csv\n",
            "Training accuracy: 0.8855 | Testing accuracy: 0.6381\n",
            "\n",
            "Running TabNet: n_a/n_d=8, epochs=50\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 44 and best_val_accuracy = 0.88248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 epoch completed. (Model training finished for n_a=8)\n",
            "Saved: 8na_50epch.csv\n",
            "Training accuracy: 0.8864 | Testing accuracy: 0.6640\n",
            "\n",
            "Running TabNet: n_a/n_d=16, epochs=5\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 4 and best_val_accuracy = 0.84046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 epoch completed. (Model training finished for n_a=16)\n",
            "Saved: 16na_5epch.csv\n",
            "Training accuracy: 0.8426 | Testing accuracy: 0.6596\n",
            "\n",
            "Running TabNet: n_a/n_d=16, epochs=10\n",
            "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_accuracy = 0.87442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 epoch completed. (Model training finished for n_a=16)\n",
            "Saved: 16na_10epch.csv\n",
            "Training accuracy: 0.8771 | Testing accuracy: 0.6444\n",
            "\n",
            "Running TabNet: n_a/n_d=16, epochs=20\n",
            "Stop training because you reached max_epochs = 20 with best_epoch = 19 and best_val_accuracy = 0.87822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 epoch completed. (Model training finished for n_a=16)\n",
            "Saved: 16na_20epch.csv\n",
            "Training accuracy: 0.8816 | Testing accuracy: 0.6174\n",
            "\n",
            "Running TabNet: n_a/n_d=16, epochs=35\n",
            "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_accuracy = 0.88474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 epoch completed. (Model training finished for n_a=16)\n",
            "Saved: 16na_35epch.csv\n",
            "Training accuracy: 0.8888 | Testing accuracy: 0.6346\n",
            "\n",
            "Running TabNet: n_a/n_d=16, epochs=50\n",
            "\n",
            "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_accuracy = 0.88474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 epoch completed. (Model training finished for n_a=16)\n",
            "Saved: 16na_50epch.csv\n",
            "Training accuracy: 0.8888 | Testing accuracy: 0.6346\n",
            "\n",
            "Running TabNet: n_a/n_d=32, epochs=5\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 4 and best_val_accuracy = 0.84583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 epoch completed. (Model training finished for n_a=32)\n",
            "Saved: 32na_5epch.csv\n",
            "Training accuracy: 0.8475 | Testing accuracy: 0.7296\n",
            "\n",
            "Running TabNet: n_a/n_d=32, epochs=10\n",
            "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_accuracy = 0.88107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 epoch completed. (Model training finished for n_a=32)\n",
            "Saved: 32na_10epch.csv\n",
            "Training accuracy: 0.8842 | Testing accuracy: 0.6770\n",
            "\n",
            "Running TabNet: n_a/n_d=32, epochs=20\n",
            "Stop training because you reached max_epochs = 20 with best_epoch = 17 and best_val_accuracy = 0.88371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 epoch completed. (Model training finished for n_a=32)\n",
            "Saved: 32na_20epch.csv\n",
            "Training accuracy: 0.8879 | Testing accuracy: 0.7053\n",
            "\n",
            "Running TabNet: n_a/n_d=32, epochs=35\n",
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_accuracy = 0.88371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 epoch completed. (Model training finished for n_a=32)\n",
            "Saved: 32na_35epch.csv\n",
            "Training accuracy: 0.8879 | Testing accuracy: 0.7053\n",
            "\n",
            "Running TabNet: n_a/n_d=32, epochs=50\n",
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_accuracy = 0.88371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 epoch completed. (Model training finished for n_a=32)\n",
            "Saved: 32na_50epch.csv\n",
            "Training accuracy: 0.8879 | Testing accuracy: 0.7053\n",
            "\n",
            "Running TabNet: n_a/n_d=48, epochs=5\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 4 and best_val_accuracy = 0.84055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 epoch completed. (Model training finished for n_a=48)\n",
            "Saved: 48na_5epch.csv\n",
            "Training accuracy: 0.8393 | Testing accuracy: 0.6977\n",
            "\n",
            "Running TabNet: n_a/n_d=48, epochs=10\n",
            "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_accuracy = 0.87626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 epoch completed. (Model training finished for n_a=48)\n",
            "Saved: 48na_10epch.csv\n",
            "Training accuracy: 0.8798 | Testing accuracy: 0.6540\n",
            "\n",
            "Running TabNet: n_a/n_d=48, epochs=20\n",
            "Stop training because you reached max_epochs = 20 with best_epoch = 17 and best_val_accuracy = 0.88116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 epoch completed. (Model training finished for n_a=48)\n",
            "Saved: 48na_20epch.csv\n",
            "Training accuracy: 0.8849 | Testing accuracy: 0.6770\n",
            "\n",
            "Running TabNet: n_a/n_d=48, epochs=35\n",
            "Stop training because you reached max_epochs = 35 with best_epoch = 33 and best_val_accuracy = 0.88197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 epoch completed. (Model training finished for n_a=48)\n",
            "Saved: 48na_35epch.csv\n",
            "Training accuracy: 0.8874 | Testing accuracy: 0.6937\n",
            "\n",
            "Running TabNet: n_a/n_d=48, epochs=50\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 44 and best_val_accuracy = 0.88529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 epoch completed. (Model training finished for n_a=48)\n",
            "Saved: 48na_50epch.csv\n",
            "Training accuracy: 0.8909 | Testing accuracy: 0.7088\n",
            "\n",
            "Running TabNet: n_a/n_d=64, epochs=5\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 4 and best_val_accuracy = 0.8538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 epoch completed. (Model training finished for n_a=64)\n",
            "Saved: 64na_5epch.csv\n",
            "Training accuracy: 0.8536 | Testing accuracy: 0.6619\n",
            "\n",
            "Running TabNet: n_a/n_d=64, epochs=10\n",
            "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_accuracy = 0.87242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 epoch completed. (Model training finished for n_a=64)\n",
            "Saved: 64na_10epch.csv\n",
            "Training accuracy: 0.8754 | Testing accuracy: 0.6041\n",
            "\n",
            "Running TabNet: n_a/n_d=64, epochs=20\n",
            "Stop training because you reached max_epochs = 20 with best_epoch = 11 and best_val_accuracy = 0.87481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 epoch completed. (Model training finished for n_a=64)\n",
            "Saved: 64na_20epch.csv\n",
            "Training accuracy: 0.8775 | Testing accuracy: 0.6251\n",
            "\n",
            "Running TabNet: n_a/n_d=64, epochs=35\n",
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_accuracy = 0.87728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 epoch completed. (Model training finished for n_a=64)\n",
            "Saved: 64na_35epch.csv\n",
            "Training accuracy: 0.8785 | Testing accuracy: 0.6193\n",
            "\n",
            "Running TabNet: n_a/n_d=64, epochs=50\n",
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_accuracy = 0.87728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 epoch completed. (Model training finished for n_a=64)\n",
            "Saved: 64na_50epch.csv\n",
            "Training accuracy: 0.8785 | Testing accuracy: 0.6193\n",
            "All results saved to /content/drive/MyDrive/Big Data Analysis and Project - a1906525/Results/TabNet/Performance Metrics/TabNet_all_results.xlsx\n",
            "All hyperparameter combinations are complete.\n"
          ]
        }
      ]
    }
  ]
}